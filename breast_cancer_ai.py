# -*- coding: utf-8 -*-
"""Breast Cancer AI

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1heN8dsk6DFdAjgRPzq5vbLuUmtS38Gxw
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install -U pip wheel setuptools
# %pip install concrete-ml

"""Importing Libraries"""

from google.colab import drive
import os
import numpy as np
from PIL import Image
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import joblib

# Mount Google Drive
drive.mount('/content/drive')

# Path to the folder in your Google Drive
folder_path = '/content/drive/MyDrive/Skin_Data'

# List the files in the folder
files = os.listdir(folder_path)
print(files)

"""Preprocessing Data"""

# Step 1: Connect Google Drive
drive.mount('/content/gdrive')

# Step 2: Set the paths to the directories
base_path = '/content/gdrive/My Drive/Skin_Data'
cancer_training_folder = os.path.join(base_path, 'Cancer', 'Training')
non_cancer_training_folder = os.path.join(base_path, 'Non_Cancer', 'Training')
cancer_testing_folder = os.path.join(base_path, 'Cancer', 'Testing')
non_cancer_testing_folder = os.path.join(base_path, 'Non_Cancer', 'Testing')

# Step 3: Load and preprocess the images
def load_images_from_folder(folder):
    images = []
    for filename in os.listdir(folder):
        img = Image.open(os.path.join(folder, filename)).convert('L')  # Convert to grayscale
        img = img.resize((256, 256))  # Resize the image to a fixed size (adjust as needed)
        img = np.array(img)  # Convert PIL image to NumPy array
        images.append(img)
    return images

# Load and preprocess images from the training directories
cancer_train_images = load_images_from_folder(cancer_training_folder)
non_cancer_train_images = load_images_from_folder(non_cancer_training_folder)

# Load and preprocess images from the testing directories
cancer_test_images = load_images_from_folder(cancer_testing_folder)
non_cancer_test_images = load_images_from_folder(non_cancer_testing_folder)

# Step 4: Create labels for the images
cancer_labels_train = np.ones(len(cancer_train_images))  # 1 for cancer
non_cancer_labels_train = np.zeros(len(non_cancer_train_images))  # 0 for non-cancer
cancer_labels_test = np.ones(len(cancer_test_images))
non_cancer_labels_test = np.zeros(len(non_cancer_test_images))

# Step 5: Split the data into training and testing sets
X_train = np.concatenate((cancer_train_images, non_cancer_train_images), axis=0)
X_test = np.concatenate((cancer_test_images, non_cancer_test_images), axis=0)

y_train = np.concatenate((cancer_labels_train, non_cancer_labels_train), axis=0)
y_test = np.concatenate((cancer_labels_test, non_cancer_labels_test), axis=0)

# Optionally, shuffle the data
shuffle_indices = np.arange(X_train.shape[0])
np.random.shuffle(shuffle_indices)

X_train = X_train[shuffle_indices]
y_train = y_train[shuffle_indices]

shuffle_indices = np.arange(X_test.shape[0])
np.random.shuffle(shuffle_indices)

X_test = X_test[shuffle_indices]
y_test = y_test[shuffle_indices]

X_train[0]

y_train

"""Training Model - Normal Model"""

# Step 1: Connect Google Drive
drive.mount('/content/gdrive')

# Step 2: Set the paths to the directories
base_path = '/content/gdrive/My Drive/Skin_Data'
cancer_training_folder = os.path.join(base_path, 'Cancer', 'Training')
non_cancer_training_folder = os.path.join(base_path, 'Non_Cancer', 'Training')
cancer_testing_folder = os.path.join(base_path, 'Cancer', 'Testing')
non_cancer_testing_folder = os.path.join(base_path, 'Non_Cancer', 'Testing')

# Step 3: Load and preprocess the images
def load_images_from_folder(folder):
    images = []
    for filename in os.listdir(folder):
        img = Image.open(os.path.join(folder, filename)).convert('L')  # Convert to grayscale
        img = img.resize((256, 256))  # Resize the image to a fixed size (adjust as needed)
        img = np.array(img)  # Convert PIL image to NumPy array
        images.append(img)
    return images

# Load and preprocess images from the training directories
cancer_train_images = load_images_from_folder(cancer_training_folder)
non_cancer_train_images = load_images_from_folder(non_cancer_training_folder)

# Load and preprocess images from the testing directories
cancer_test_images = load_images_from_folder(cancer_testing_folder)
non_cancer_test_images = load_images_from_folder(non_cancer_testing_folder)

# Step 4: Create labels for the images
cancer_labels_train = np.ones(len(cancer_train_images))  # 1 for cancer
non_cancer_labels_train = np.zeros(len(non_cancer_train_images))  # 0 for non-cancer
cancer_labels_test = np.ones(len(cancer_test_images))
non_cancer_labels_test = np.zeros(len(non_cancer_test_images))

# Step 5: Flatten the images
def flatten_images(images):
    return np.array([image.flatten() for image in images])

X_train_cancer_flattened = flatten_images(cancer_train_images)
X_train_non_cancer_flattened = flatten_images(non_cancer_train_images)
X_test_cancer_flattened = flatten_images(cancer_test_images)
X_test_non_cancer_flattened = flatten_images(non_cancer_test_images)

# Step 6: Combine the flattened images and labels
X_train = np.concatenate((X_train_cancer_flattened, X_train_non_cancer_flattened), axis=0)
X_test = np.concatenate((X_test_cancer_flattened, X_test_non_cancer_flattened), axis=0)

y_train = np.concatenate((cancer_labels_train, non_cancer_labels_train), axis=0)
y_test = np.concatenate((cancer_labels_test, non_cancer_labels_test), axis=0)

# Optionally, shuffle the data
shuffle_indices = np.arange(X_train.shape[0])
np.random.shuffle(shuffle_indices)

X_train = X_train[shuffle_indices]
y_train = y_train[shuffle_indices]

shuffle_indices = np.arange(X_test.shape[0])
np.random.shuffle(shuffle_indices)

X_test = X_test[shuffle_indices]
y_test = y_test[shuffle_indices]

# Step 7: Train the logistic regression model
logistic_regression_model = LogisticRegression()
logistic_regression_model.fit(X_train, y_train)

# Step 8: Predict the target labels on the test set
y_pred = logistic_regression_model.predict(X_test)

# Step 9: Evaluate the model's accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Set the path to save the model in Google Drive
model_filepath = 'logistic_regression_model_weights.joblib'

# Save the model using joblib
joblib.dump(logistic_regression_model, model_filepath)

# Now, the model weights are saved in the specified 'model_filepath' on your Google Drive.